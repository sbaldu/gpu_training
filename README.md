# Introduction to GPU Programming with CUDA


The CUDA Runtime API reference manual is a very useful source of information:
<a href="http://docs.nvidia.com/cuda/cuda-runtime-api/index.html" target="_blank">http://docs.nvidia.com/cuda/cuda-runtime-api/index.html</a>


Check that your environment is correctly configured to compile CUDA code by running:
```bash
$ nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2025 NVIDIA Corporation
Built on Tue_May_27_02:21:03_PDT_2025
Cuda compilation tools, release 12.9, V12.9.86
Build cuda_12.9.r12.9/compiler.36037853_0
```

```bash
git clone https://github.com/felicepantaleo/gpu_training.git
```

Compile and run the `deviceQuery` application:
```bash
$ cd hands-on/utils/deviceQuery
$ make
```

You can get some useful information about the features and the limits that you will find on the device you will be running your code on. For example:

```shell
$ ./deviceQuery 
./deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "Tesla V100-SXM2-32GB"
  CUDA Driver Version / Runtime Version          12.9 / 12.9
  CUDA Capability Major/Minor version number:    7.0
  Total amount of global memory:                 32494 MBytes (34072559616 bytes)
  (80) Multiprocessors, ( 64) CUDA Cores/MP:     5120 CUDA Cores
  GPU Max Clock rate:                            1530 MHz (1.53 GHz)
  Memory Clock rate:                             877 Mhz
  Memory Bus Width:                              4096-bit
  L2 Cache Size:                                 6291456 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total shared memory per multiprocessor:        98304 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Managed Memory:                Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 5
  Compute Mode:
     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 12.9, CUDA Runtime Version = 12.9, NumDevs = 1
Result = PASS   
```

Some of you are sharing the same machine and some time measurements can be influenced by other users running at the very same moment. It can be necessary to run time measurements multiple times.


# GPU Training â€” Handsâ€‘On Exercises

These short, selfâ€‘contained labs walk students from CUDA basics to a tiny predatorâ€“prey simulation.  Every exercise follows the same workflow:

```
1. Fill in all  â–ºâ–ºâ–ºÂ TODOâ€¯â—„â—„â—„  and/or kernel bodies.
2. Build with the line shown in the banner comment.
3. Run â†’Â the program prints â€œâ€¦PASSED ğŸ‰â€ when assertions succeed.
```

All code lives under `gpu_training/` and compiles on CUDAÂ 12â€¯+â€¯gccÂ 13 (UbuntuÂ 22.04).

---

## Exerciseâ€¯1 â€“Â CUDA Memory Model ğŸ§ 

*GoalÂ â€“ feel the separation between CPU (host) and GPU (device) address spaces.*

| Step | What you implement                                   |
| ---- | ---------------------------------------------------- |
| â€¯1   | `cudaMallocAsync` two device buffers `d_a` and `d_b` |
| â€¯2   | Copy host array `h_a â†’ d_a`                          |
| â€¯3   | Copy device array `d_a â†’ d_b` (deviceâ€‘toâ€‘device)     |
| â€¯4   | Copy back `d_b â†’ h_a`                                |
| â€¯5   | Free `d_a`, `d_b` with `cudaFreeAsync`               |

```bash
nvcc -std=c++20 memory_model.cu -o ex01
./ex01   # prints â€œExerciseÂ 1 â€“ memory model: PASSED ğŸ‰â€
```

### âœï¸Â Variation

Add a nonâ€‘blocking version using **streams** + `cudaMemcpyAsync` and time a 100â€¯MB Hâ†”D copy to estimate PCIe bandwidth.

---

## Exerciseâ€¯2 â€“Â Launch Your First Kernel ğŸš€

*GoalÂ â€“ understand grid/block configuration and indexing.*

1. `cudaMallocAsync` a device array `d_a[N]`
2. Launch a **1â€‘D grid** of **1â€‘D blocks**

   ```c++
   d_a[i] = i + 42;  // each thread writes one element
   ```
3. Copy back, verify, free the memory.

Compile & run:

```bash
nvcc -std=c++20 launch_kernel.cu -o ex02 && ./ex02
```

**Hint:** Global thread index = `blockIdx.x * blockDim.x + threadIdx.x`.

---

## Exerciseâ€¯3 â€“Â 2â€‘D Grid & Block ğŸ§®

*GoalÂ â€“ move from 1â€‘D to 2â€‘D indexing.*

Matrix **M\[numRows Ã— numCols]**.

| Task | Detail                                                                                          |
| ---- | ----------------------------------------------------------------------------------------------- |
| 1    | Set `numRows`, `numCols` (start with 4Â Ã—Â 4, then 19Â Ã—Â 67).                                      |
| 2    | Launch a **2â€‘D grid of 2â€‘D blocks** so each thread writes<br>`M[row,col] = row * numCols + col` |
| 3    | Copy to host, assert correctness                                                                |
| 4    | Experiment: fix block =Â `16Ã—16`, compute `blocksPerGrid` with ceiling division                  |

Compile:

```bash
nvcc -std=c++20 ex03_fill_matrix.cu -o ex03 && ./ex03
```

---

## Exerciseâ€¯4 â€“Â Parallel Reduction âˆ‘

*GoalÂ â€“ sum a 1â€‘D array faster than the CPU.*

> **Rule of thumb:** keep each block powerâ€‘ofâ€‘two and reduce in shared memory.

1. KernelÂ #1: each block loads its slice, does **sharedâ€‘mem tree reduction**, writes one partial sum.
2. KernelÂ #2: single block reduces those partials into the final total.
3. Copy result, compare to `std::accumulate`.  

*Bonus*: oneâ€‘step reduction (single kernel).

---

## Parallel Challenge â€“Â **The Circle of Life** ğŸŒ±ğŸ°ğŸ¦Š

A toroidal predatorâ€“prey world.  Build the starter **CPU version** first, then:

* **Profile** hotspot (`update_grid_sequential`).
* **Port** to CUDA.

Reference CPU build:

```bash
g++ -std=c++20 -O2 circle_of_life.cpp -lgif -o circle_of_life
./circle_of_life --width 256 --height 256 --seed 42
```

GPU build template:

```bash
nvcc -std=c++20 -O2 circle_of_life.cu -lgif -o circle_of_life_cuda
```
---

### Common Pitfalls & Tips

* **Always** `cudaGetLastError()` after a launch when debugging.
* Use **asserts** on the host to check results before optimising.
* Remember `cudaStreamSynchronize()` before timing or freeing async memory.
* `dim3` defaults `z=1`; you almost never need a nonâ€‘unit Z for these labs.
* For reductions, `blockDim.x` **must** be a powerâ€‘ofâ€‘two when you half the stride each step.

Good luck & happy hacking! 
